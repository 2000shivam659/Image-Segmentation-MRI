{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Image Segmentation**"
      ],
      "metadata": {
        "id": "tm51rRaaAz1y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIpqSnXtdmWF"
      },
      "outputs": [],
      "source": [
        "# Import all libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "import keras.backend as K\n",
        "from niwidgets import NiftiWidget\n",
        "\n",
        "# Define the dataset path\n",
        "folder_path = '/content/drive/My Drive/Data'\n",
        "files = os.listdir(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in the folder\n",
        "file_names = os.listdir(folder_path)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "train_files, test_files = train_test_split(file_names, test_size=0.1, random_state=42)\n",
        "\n",
        "print(len(train_files))\n",
        "print(len(test_files))"
      ],
      "metadata": {
        "id": "UMz80sVBKOIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pre-processing of 3D images**"
      ],
      "metadata": {
        "id": "mEKSDC1sSRja"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-max scaling\n",
        "def normalizeImageIntensityRange(img):\n",
        "  min_val = np.min(img)\n",
        "  max_val = np.max(img)\n",
        "  normalized_data = (img - min_val) / (max_val - min_val)\n",
        "  return normalized_data"
      ],
      "metadata": {
        "id": "SIpG89oEdCH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read image or mask volume\n",
        "def readImageVolume(imgPath, normalize=False):\n",
        "    img = nib.load(imgPath).get_fdata()\n",
        "    return normalizeImageIntensityRange(img)"
      ],
      "metadata": {
        "id": "ji9xSQRtV2kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save volume slice to file\n",
        "def saveSlice(img, fname, path):\n",
        "    img = np.uint8(img * 255)\n",
        "    fout = os.path.join(path, f'{fname}.png')\n",
        "    cv2.imwrite(fout, img)\n",
        "    print(f'[+] Slice saved: {fout}', end='\\r')"
      ],
      "metadata": {
        "id": "3LiyYYoNJfQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SLICE_X = True\n",
        "SLICE_Y = True\n",
        "SLICE_Z = False\n",
        "\n",
        "SLICE_DECIMATE_IDENTIFIER = 3\n",
        "\n",
        "# Slice image in all directions and save\n",
        "def sliceAndSaveVolumeImage(vol, fname, path):\n",
        "    (dimx, dimy, dimz) = vol.shape\n",
        "    print(dimx, dimy, dimz)\n",
        "    cnt = 0\n",
        "    if SLICE_X:\n",
        "        cnt += dimx\n",
        "        print('Slicing X: ')\n",
        "        for i in range(dimx):\n",
        "            saveSlice(vol[i,:,:], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_x', path)\n",
        "\n",
        "    if SLICE_Y:\n",
        "        cnt += dimy\n",
        "        print('Slicing Y: ')\n",
        "        for i in range(dimy):\n",
        "            saveSlice(vol[:,i,:], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_y', path)\n",
        "\n",
        "    if SLICE_Z:\n",
        "        cnt += dimz\n",
        "        print('Slicing Z: ')\n",
        "        for i in range(dimz):\n",
        "            saveSlice(vol[:,:,i], fname+f'-slice{str(i).zfill(SLICE_DECIMATE_IDENTIFIER)}_z', path)\n",
        "    return cnt"
      ],
      "metadata": {
        "id": "UeWgv7h6k9Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and process image volumes\n",
        "def imageVolumes(files):\n",
        "  for folder in files:\n",
        "    path = os.path.join(folder_path, folder)\n",
        "    for file in sorted(os.listdir(path)):\n",
        "      if \"ROI\" not in file:\n",
        "        img = readImageVolume(os.path.join(path, file), False)\n",
        "        print(file, img.shape, np.sum(img.shape), np.min(img), np.max(img))\n",
        "        numOfSlices = sliceAndSaveVolumeImage(img, os.path.basename(path), imageOutput)\n",
        "        print(f'\\n{file}, {numOfSlices} slices created \\n')"
      ],
      "metadata": {
        "id": "BCZtUblQV-F-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and process image mask volumes\n",
        "def imagemaskVolumes(files):\n",
        "  for folder in files:\n",
        "    path = os.path.join(folder_path, folder)\n",
        "    for file in sorted(os.listdir(path)):\n",
        "      if \"ROI\" in file:\n",
        "        img = readImageVolume(os.path.join(path, file), False)\n",
        "        print(file, img.shape, np.sum(img.shape), np.min(img), np.max(img))\n",
        "        numOfSlices = sliceAndSaveVolumeImage(img, os.path.basename(path), imagemaskOutput)\n",
        "        print(f'\\n{file}, {numOfSlices} slices created \\n')"
      ],
      "metadata": {
        "id": "0TG86QSYtTOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a file for saving the image and mask for train\n",
        "imageOutput = '/content/train/img'\n",
        "os.makedirs(imageOutput, exist_ok=True)\n",
        "imagemaskOutput = '/content/train/mask'\n",
        "os.makedirs(imagemaskOutput, exist_ok=True)\n",
        "\n",
        "# Process image and  mask for trianing files\n",
        "imageVolumes(train_files)\n",
        "imagemaskVolumes(train_files)"
      ],
      "metadata": {
        "id": "XGqBd4bQtvFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a file for saving the image and mask for validation\n",
        "imageOutput = '/content/test/img'\n",
        "os.makedirs(imageOutput, exist_ok=True)\n",
        "imagemaskOutput = '/content/test/mask'\n",
        "os.makedirs(imagemaskOutput, exist_ok=True)\n",
        "\n",
        "# Process image and  mask for testing files\n",
        "imageVolumes(test_files)\n",
        "imagemaskVolumes(test_files)"
      ],
      "metadata": {
        "id": "Ph7xvH5CKAsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Define constants\n",
        "SEED = 909\n",
        "BATCH_SIZE_TRAIN = 16\n",
        "BATCH_SIZE_TEST = 16\n",
        "\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "IMG_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
        "\n",
        "data_dir_train_image = 'train/img'\n",
        "data_dir_train_mask = 'train/mask'\n",
        "data_dir_test_image = 'test/img'\n",
        "data_dir_test_mask = 'test/mask'\n",
        "\n",
        "NUM_TRAIN = 16384\n",
        "NUM_TEST = 5120\n",
        "\n",
        "NUM_OF_EPOCHS = 30"
      ],
      "metadata": {
        "id": "dY6C3kG4NMHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data agumentation for training images and mask\n",
        "def create_segmentation_generator_train(img_path, msk_path, BATCH_SIZE):\n",
        "    img_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=90,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        zoom_range=0.3)\n",
        "\n",
        "    img_generator = img_datagen.flow_from_directory(\n",
        "        img_path,\n",
        "        target_size=IMG_SIZE,\n",
        "        class_mode=None,\n",
        "        color_mode='grayscale',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED)\n",
        "    msk_generator = img_datagen.flow_from_directory(\n",
        "        msk_path,\n",
        "        target_size=IMG_SIZE,\n",
        "        class_mode=None,\n",
        "        color_mode='grayscale',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED)\n",
        "\n",
        "    return zip(img_generator, msk_generator)"
      ],
      "metadata": {
        "id": "CIrUzjsFQpHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data agumentation for testing images and mask\n",
        "def create_segmentation_generator_test(img_path, msk_path, BATCH_SIZE):\n",
        "    img_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    img_generator = img_datagen.flow_from_directory(\n",
        "        img_path,\n",
        "        target_size=IMG_SIZE,\n",
        "        class_mode=None,\n",
        "        color_mode='grayscale',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED)\n",
        "    msk_generator = img_datagen.flow_from_directory(\n",
        "        msk_path,\n",
        "        target_size=IMG_SIZE,\n",
        "        class_mode=None,\n",
        "        color_mode='grayscale',\n",
        "        batch_size=BATCH_SIZE,\n",
        "        seed=SEED)\n",
        "\n",
        "    return zip(img_generator, msk_generator)"
      ],
      "metadata": {
        "id": "fPMK0dmkYk26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Call the traing images\n",
        "train_generator = create_segmentation_generator_train(\n",
        "    data_dir_train_image,\n",
        "    data_dir_train_mask,\n",
        "    BATCH_SIZE_TRAIN)\n",
        "\n",
        "# Call the testing images\n",
        "test_generator = create_segmentation_generator_test(\n",
        "    data_dir_test_image,\n",
        "    data_dir_test_mask,\n",
        "    BATCH_SIZE_TEST)"
      ],
      "metadata": {
        "id": "skBxE9ehYomM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image after agumentation\n",
        "def display(display_list):\n",
        "    plt.figure(figsize=(15,15))\n",
        "\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]), cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "__B-zn5jaMW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image, True mask and Predicted mask from test_generator\n",
        "def show_dataset(datagen, num=1):\n",
        "    for i in range(0,num):\n",
        "        image,mask = next(datagen)\n",
        "        display([image[0], mask[0]])"
      ],
      "metadata": {
        "id": "9C7_UfGfAYTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_dataset(train_generator, 2)"
      ],
      "metadata": {
        "id": "vPAI6FGwAYOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UG_QdxH5AnQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the dataset**"
      ],
      "metadata": {
        "id": "4Ljua7nZSJG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Unet model from scratch\n",
        "def unet(n_levels, initial_features=32, n_blocks=2, kernel_size=3, pooling_size=2, in_channels=1, out_channels=1):\n",
        "    inputs = keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, in_channels))\n",
        "    x = inputs\n",
        "\n",
        "    convpars = dict(kernel_size=kernel_size, activation='relu', padding='same', kernel_initializer='he_normal')\n",
        "\n",
        "    #downstream\n",
        "    skips = {}\n",
        "    for level in range(n_levels):\n",
        "        for _ in range(n_blocks):\n",
        "            x = keras.layers.Conv2D(initial_features * 2 ** level, **convpars)(x)\n",
        "            if _ == 0:\n",
        "                x = keras.layers.Dropout(0.25)(x)\n",
        "        if level < n_levels - 1:\n",
        "            skips[level] = x\n",
        "            x = keras.layers.Normalization()(x)\n",
        "            x = keras.layers.MaxPool2D(pooling_size)(x)\n",
        "\n",
        "    # upstream\n",
        "    for level in reversed(range(n_levels-1)):\n",
        "        x = keras.layers.Conv2DTranspose(initial_features * 2 ** level, strides=pooling_size, **convpars)(x)\n",
        "        x = keras.layers.Concatenate()([x, skips[level]])\n",
        "        for _ in range(n_blocks):\n",
        "            x = keras.layers.Normalization()(x)\n",
        "            x = keras.layers.Conv2D(initial_features * 2 ** level, **convpars)(x)\n",
        "\n",
        "    # output\n",
        "    activation = 'sigmoid' if out_channels == 1 else 'softmax'\n",
        "    x = keras.layers.Conv2D(out_channels, kernel_size=1, activation=activation, padding='same')(x)\n",
        "\n",
        "    return keras.Model(inputs=[inputs], outputs=[x], name=f'UNET-L{n_levels}-F{initial_features}')\n",
        "\n",
        "# Defining dice loss for image segmantation\n",
        "def dice_loss(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    union = K.sum(y_true) + K.sum(y_pred)\n",
        "    dice_loss = 1.0 - (2.0 * intersection + K.epsilon()) / (union + K.epsilon())\n",
        "    return dice_loss"
      ],
      "metadata": {
        "id": "8RpzPiTlAYMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define constants\n",
        "EPOCH_STEP_TRAIN = NUM_TRAIN // BATCH_SIZE_TRAIN\n",
        "EPOCH_STEP_TEST = NUM_TEST // BATCH_SIZE_TEST\n",
        "\n",
        "model = unet(4)\n",
        "model.compile(optimizer='adam', loss=dice_loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GpDEZ9F8AYJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of overall model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "aWoOK8tSAYAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit_generator(\n",
        "    generator=train_generator,\n",
        "    steps_per_epoch=EPOCH_STEP_TRAIN,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=EPOCH_STEP_TEST,\n",
        "    epochs=NUM_OF_EPOCHS)"
      ],
      "metadata": {
        "id": "q8Ub7xcHAXyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model as an HDF5 file\n",
        "model.save(f'UNET-ToothSegmentation_{IMAGE_HEIGHT}_{IMAGE_WIDTH}.h5')"
      ],
      "metadata": {
        "id": "5FLbm-IrI4RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_prediction(datagen, num=1):\n",
        "    for i in range(0,num):\n",
        "        image,mask = next(datagen)\n",
        "        pred_mask = model.predict(image)[0] > 0.5\n",
        "        display([image[0], mask[0], pred_mask])"
      ],
      "metadata": {
        "id": "RVaOyhN4A53Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_prediction(test_generator, 3)"
      ],
      "metadata": {
        "id": "ui7hJaAPBr_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0VOmz5VeBwq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "IMG_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
        "\n",
        "# For single slicing prediction\n",
        "sliceIndex = 24"
      ],
      "metadata": {
        "id": "XphoKTYICia6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Min-max scaling\n",
        "def normalizeImageIntensityRange(img):\n",
        "  min_val = np.min(img)\n",
        "  max_val = np.max(img)\n",
        "  normalized_data = (img - min_val) / (max_val - min_val)\n",
        "  return normalized_data"
      ],
      "metadata": {
        "id": "_7ZDv-9YBwni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick any image from test to predict the mask\n",
        "test"
      ],
      "metadata": {
        "id": "Pk-ccMKkNoTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick any image\n",
        "targetName = 'N002'\n",
        "targetImagePath = f'/content/drive/My Drive/Data/{targetName}/{targetName}.nii.gz'\n",
        "targetMaskPath  = f'/content/drive/My Drive/Data/{targetName}/{targetName}_ROI.nii.gz'\n",
        "\n",
        "imgTargetNii = nib.load(targetImagePath)\n",
        "imgMaskNii = nib.load(targetMaskPath)\n",
        "\n",
        "imgTarget = normalizeImageIntensityRange(imgTargetNii.get_fdata())\n",
        "imgMask = imgMaskNii.get_fdata()"
      ],
      "metadata": {
        "id": "nT-7ihxdBwku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = load_model(f'UNET-ToothSegmentation_{IMAGE_HEIGHT}_{IMAGE_WIDTH}.h5')"
      ],
      "metadata": {
        "id": "3MM2Y787BwhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaleImg(img, height, width):\n",
        "    return cv2.resize(img, dsize=(width, height), interpolation=cv2.INTER_LINEAR)"
      ],
      "metadata": {
        "id": "SuXa5wAnJiwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single Slicing Prediction**"
      ],
      "metadata": {
        "id": "K1cg0wBXJaIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show input image slice\n",
        "plt.figure(figsize=(15,15))\n",
        "imgSlice = imgTarget[sliceIndex,:,:]\n",
        "imgDimX, imgDimY = imgSlice.shape\n",
        "imgSliceScaled = scaleImg(imgSlice, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(imgSlice, cmap='gray')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(imgSliceScaled, cmap='gray')\n",
        "plt.show()\n",
        "imgSlice.shape, imgSliceScaled.shape"
      ],
      "metadata": {
        "id": "q8btCsm1JS9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show input mask slice\n",
        "plt.figure(figsize=(15,15))\n",
        "maskSlice = imgMask[sliceIndex,:,:]\n",
        "maskSliceScaled = scaleImg(maskSlice, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(maskSlice, cmap='gray')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(maskSliceScaled, cmap='gray')\n",
        "plt.show()\n",
        "maskSlice.shape, maskSliceScaled.shape"
      ],
      "metadata": {
        "id": "rH-uZqu2JSdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with UNET model\n",
        "plt.figure(figsize=(15,15))\n",
        "imageInput = imgSliceScaled[np.newaxis,:,:,np.newaxis]\n",
        "maskPredict = model.predict(imageInput)[0,:,:,0]\n",
        "maskPredictScaled = scaleImg(maskPredict, imgDimX, imgDimY)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(maskPredict, cmap='gray')\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(maskPredictScaled, cmap='gray')\n",
        "plt.show()\n",
        "maskPredictScaled.shape, maskPredict.shape"
      ],
      "metadata": {
        "id": "dIZvr9zQJu6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction of full volume**"
      ],
      "metadata": {
        "id": "_1GtfYncKaG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SLICE_X = True\n",
        "SLICE_Y = True\n",
        "SLICE_Z = False\n",
        "\n",
        "# Slice image in all directions\n",
        "def predictVolume(inImg, toBin=True):\n",
        "    (xMax, yMax, zMax) = inImg.shape\n",
        "\n",
        "    outImgX = np.zeros((xMax, yMax, zMax))\n",
        "    outImgY = np.zeros((xMax, yMax, zMax))\n",
        "    outImgZ = np.zeros((xMax, yMax, zMax))\n",
        "\n",
        "    cnt = 0.0\n",
        "    if SLICE_X:\n",
        "        cnt += 1.0\n",
        "        for i in range(xMax):\n",
        "            img = scaleImg(inImg[i,:,:], IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n",
        "            tmp = model.predict(img)[0,:,:,0]\n",
        "            outImgX[i,:,:] = scaleImg(tmp, yMax, zMax)\n",
        "    if SLICE_Y:\n",
        "        cnt += 1.0\n",
        "        for i in range(yMax):\n",
        "            img = scaleImg(inImg[:,i,:], IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n",
        "            tmp = model.predict(img)[0,:,:,0]\n",
        "            outImgY[:,i,:] = scaleImg(tmp, xMax, zMax)\n",
        "    if SLICE_Z:\n",
        "        cnt += 1.0\n",
        "        for i in range(zMax):\n",
        "            img = scaleImg(inImg[:,:,i], IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n",
        "            tmp = model.predict(img)[0,:,:,0]\n",
        "            outImgZ[:,:,i] = scaleImg(tmp, xMax, yMax)\n",
        "\n",
        "    outImg = (outImgX + outImgY + outImgZ)/cnt\n",
        "    if(toBin):\n",
        "        outImg[outImg>0.5] = 1.0\n",
        "        outImg[outImg<=0.5] = 0.0\n",
        "    return outImg"
      ],
      "metadata": {
        "id": "AWRbUJ6dJ0s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predImg = predictVolume(imgTarget)"
      ],
      "metadata": {
        "id": "ZEmUZ-FJLP9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_widget = NiftiWidget(imgTargetNii)\n",
        "my_widget.nifti_plotter(colormap='gray')"
      ],
      "metadata": {
        "id": "9Pi4u6QHLYC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_widget = NiftiWidget(nib.dataobj_images.DataobjImage(predImg))\n",
        "my_widget.nifti_plotter(colormap='gray')"
      ],
      "metadata": {
        "id": "WdetYEn4LXyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_widget = NiftiWidget(imgMaskNii)\n",
        "my_widget.nifti_plotter(colormap='gray')"
      ],
      "metadata": {
        "id": "TQ5XFVpgLXvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "deZ9w9CrMRMs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
